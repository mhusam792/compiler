{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def is_image_with_pillow(file_path):\n",
    "    try:\n",
    "        with Image.open(file_path):\n",
    "            return True\n",
    "    except (IOError, SyntaxError):\n",
    "        return False\n",
    "\n",
    "\n",
    "print(is_image_with_pillow(\"/home/hossam/final_app/requirements/libraries.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "  <title>Index of /resources/</title>\n",
      "  <style>\n",
      "    body {\n",
      "        font-family: \"Segoe UI\", \"Segoe WP\", \"Helvetica Neue\", 'RobotoRegular', sans-serif;\n",
      "        font-size: 14px;}\n",
      "    header h1 {\n",
      "        font-family: \"Segoe UI Light\", \"Helvetica Neue\", 'RobotoLight', \"Segoe UI\", \"Segoe WP\", sans-serif;\n",
      "        font-size: 28px;\n",
      "        font-weight: 100;\n",
      "        margin-top: 5px;\n",
      "        margin-bottom: 0px;}\n",
      "    #index {\n",
      "        border-collapse: separate;\n",
      "        border-spacing: 0;\n",
      "        margin: 0 0 20px; }\n",
      "    #index th {\n",
      "        vertical-align: bottom;\n",
      "        padding: 10px 5px 5px 5px;\n",
      "        font-weight: 400;\n",
      "        color: #a0a0a0;\n",
      "        text-align: center; }\n",
      "    #index td { padding: 3px 10px; }\n",
      "    #index th, #index td {\n",
      "        border-right: 1px #ddd solid;\n",
      "        border-bottom: 1px #ddd solid;\n",
      "        border-left: 1px transparent solid;\n",
      "        border-top: 1px transparent solid;\n",
      "        box-sizing: border-box; }\n",
      "    #index th:last-child, #index td:last-child {\n",
      "        border-right: 1px transparent solid; }\n",
      "    #index td.length, td.modified { text-align:right; }\n",
      "    a { color:#1ba1e2;text-decoration:none; }\n",
      "    a:hover { color:#13709e;text-decoration:underline; }\n",
      "  </style>\n",
      "</head>\n",
      "<body>\n",
      "  <section id=\"main\">\n",
      "    <header><h1>Index of <a href=\"/\">/</a><a href=\"/resources/\">resources/</a></h1></header>\n",
      "    <table id=\"index\" summary=\"The list of files in the given directory.  Column headers are listed in the first row.\">\n",
      "    <thead>\n",
      "      <tr><th abbr=\"Name\">Name</th><th abbr=\"Size\">Size</th><th abbr=\"Modified\">Last Modified</th></tr>\n",
      "    </thead>\n",
      "    <tbody>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./0bc3a546-953c-490c-ba1e-3cd26fd0e7d4.jpg\">0bc3a546-953c-490c-ba1e-3cd26fd0e7d4.jpg</a></td>\n",
      "        <td class=\"length\">605,597</td>\n",
      "        <td class=\"modified\">2/29/2024 4:44:17 PM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./0f5faf27-e7e3-4f93-9b3c-877e9f3e6556.jpg\">0f5faf27-e7e3-4f93-9b3c-877e9f3e6556.jpg</a></td>\n",
      "        <td class=\"length\">14,415</td>\n",
      "        <td class=\"modified\">3/4/2024 11:17:29 PM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./19d5c60b-c327-433d-8e74-2752ddc0502c.jpg\">19d5c60b-c327-433d-8e74-2752ddc0502c.jpg</a></td>\n",
      "        <td class=\"length\">365,916</td>\n",
      "        <td class=\"modified\">2/29/2024 6:00:05 PM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./2f91a2f7-ec3a-4605-83d4-8a8e2974c656.jpg\">2f91a2f7-ec3a-4605-83d4-8a8e2974c656.jpg</a></td>\n",
      "        <td class=\"length\">32,445</td>\n",
      "        <td class=\"modified\">3/1/2024 8:59:34 PM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./3e6e75d8-3e8a-4956-b0c4-5461549851aa.jpg\">3e6e75d8-3e8a-4956-b0c4-5461549851aa.jpg</a></td>\n",
      "        <td class=\"length\">8,201</td>\n",
      "        <td class=\"modified\">3/4/2024 11:15:26 PM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./4e8e7478-384b-4ea8-9e5d-893949899951.jpg\">4e8e7478-384b-4ea8-9e5d-893949899951.jpg</a></td>\n",
      "        <td class=\"length\">13,641</td>\n",
      "        <td class=\"modified\">3/5/2024 10:03:57 AM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./5ca17efd-86e8-42d5-a91f-b179a4a87df6.jpg\">5ca17efd-86e8-42d5-a91f-b179a4a87df6.jpg</a></td>\n",
      "        <td class=\"length\">9,067</td>\n",
      "        <td class=\"modified\">3/5/2024 12:26:29 AM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./6db529d3-20ca-44ff-9134-d6163965b75a.jpg\">6db529d3-20ca-44ff-9134-d6163965b75a.jpg</a></td>\n",
      "        <td class=\"length\">40,144</td>\n",
      "        <td class=\"modified\">3/1/2024 9:02:25 PM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./81c003e2-e9cd-4fdc-a45d-a1c6239c4138.jpg\">81c003e2-e9cd-4fdc-a45d-a1c6239c4138.jpg</a></td>\n",
      "        <td class=\"length\">62,480</td>\n",
      "        <td class=\"modified\">3/5/2024 9:56:39 AM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./8354ce75-26cc-47a2-a3bd-e9481a40a65c.jpg\">8354ce75-26cc-47a2-a3bd-e9481a40a65c.jpg</a></td>\n",
      "        <td class=\"length\">63,737</td>\n",
      "        <td class=\"modified\">3/5/2024 9:54:33 AM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./8b9f2781-f727-45ff-89ac-220bad6aaab2.jpg\">8b9f2781-f727-45ff-89ac-220bad6aaab2.jpg</a></td>\n",
      "        <td class=\"length\">1,458,008</td>\n",
      "        <td class=\"modified\">2/29/2024 5:27:15 AM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./b9ad6e18-41d7-4649-b8c2-a4a83608c25d.jpg\">b9ad6e18-41d7-4649-b8c2-a4a83608c25d.jpg</a></td>\n",
      "        <td class=\"length\">173,145</td>\n",
      "        <td class=\"modified\">2/29/2024 6:00:48 PM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./c25fa6de-da52-4443-83ae-ebfe0ea49239.jpg\">c25fa6de-da52-4443-83ae-ebfe0ea49239.jpg</a></td>\n",
      "        <td class=\"length\">43,153</td>\n",
      "        <td class=\"modified\">3/1/2024 8:54:42 PM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./ccaee2c8-8c3b-4fd0-9386-5ee6594e0332.jpg\">ccaee2c8-8c3b-4fd0-9386-5ee6594e0332.jpg</a></td>\n",
      "        <td class=\"length\">40,953</td>\n",
      "        <td class=\"modified\">3/1/2024 6:40:19 PM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./d0457a22-9caa-4e58-80e6-8650c074d86a.jpg\">d0457a22-9caa-4e58-80e6-8650c074d86a.jpg</a></td>\n",
      "        <td class=\"length\">9,067</td>\n",
      "        <td class=\"modified\">3/4/2024 11:13:32 PM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./d21c7e8c-cdc2-491b-97a5-d00988895141.jpg\">d21c7e8c-cdc2-491b-97a5-d00988895141.jpg</a></td>\n",
      "        <td class=\"length\">6,747</td>\n",
      "        <td class=\"modified\">3/5/2024 12:23:47 AM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "      <tr class=\"file\">\n",
      "        <td class=\"name\"><a href=\"./f08d2f8b-4254-4048-94f2-5c070e304927.jpg\">f08d2f8b-4254-4048-94f2-5c070e304927.jpg</a></td>\n",
      "        <td class=\"length\">40,953</td>\n",
      "        <td class=\"modified\">3/1/2024 7:18:04 PM &#x2B;00:00</td>\n",
      "      </tr>\n",
      "    </tbody>\n",
      "    </table>\n",
      "  </section>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://wdw888lb-7075.uks1.devtunnels.ms/resources/\"\n",
    "\n",
    "# Make a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Print the content of the response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"find_object\": \"عامل ايه\",\n",
    "  \"founded_objects\": [\n",
    "    \"ايه اخبارك\", \"معاك الكتاب؟\", \"كنت تحت فى الشارع\", \"الحمدلله تمام\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def list_folder_contents(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for 4xx and 5xx status codes\n",
    "\n",
    "        # Assuming the server returns a JSON response containing a list of files and directories\n",
    "        folder_contents = response.json()\n",
    "        \n",
    "        # Print or process the list of files and directories\n",
    "        for item in folder_contents:\n",
    "            print(item)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Replace the URL with the actual URL of the folder on your server\n",
    "folder_url = \"https://wdw888lb-7075.uks1.devtunnels.ms/resources\"\n",
    "list_folder_contents(folder_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import webbrowser\n",
    "\n",
    "def extract_image_urls(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "\n",
    "    image_urls = []\n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[1:]:  # Skip the header row\n",
    "            columns = row.find_all('td')\n",
    "            image_url = columns[0].text.strip()\n",
    "            image_urls.append(image_url)\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "def open_images(image_urls):\n",
    "    for image_url in image_urls:\n",
    "        webbrowser.open(url + image_url)\n",
    "\n",
    "url = \"https://wdw888lb-7075.uks1.devtunnels.ms/resources/\"\n",
    "image_urls = extract_image_urls(url)\n",
    "open_images(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://wdw888lb-7075.uks1.devtunnels.ms/resources/0bc3a546-953c-490c-ba1e-3cd26fd0e7d4.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/0f5faf27-e7e3-4f93-9b3c-877e9f3e6556.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/19d5c60b-c327-433d-8e74-2752ddc0502c.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/2f91a2f7-ec3a-4605-83d4-8a8e2974c656.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/3e6e75d8-3e8a-4956-b0c4-5461549851aa.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/4e8e7478-384b-4ea8-9e5d-893949899951.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/5ca17efd-86e8-42d5-a91f-b179a4a87df6.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/6db529d3-20ca-44ff-9134-d6163965b75a.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/81c003e2-e9cd-4fdc-a45d-a1c6239c4138.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/8354ce75-26cc-47a2-a3bd-e9481a40a65c.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/8b9f2781-f727-45ff-89ac-220bad6aaab2.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/b9ad6e18-41d7-4649-b8c2-a4a83608c25d.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/c25fa6de-da52-4443-83ae-ebfe0ea49239.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/ccaee2c8-8c3b-4fd0-9386-5ee6594e0332.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/d0457a22-9caa-4e58-80e6-8650c074d86a.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/d21c7e8c-cdc2-491b-97a5-d00988895141.jpg', 'https://wdw888lb-7075.uks1.devtunnels.ms/resources/f08d2f8b-4254-4048-94f2-5c070e304927.jpg']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m             csv_writer\u001b[38;5;241m.\u001b[39mwriterow([image_url])\n\u001b[1;32m     29\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://wdw888lb-7075.uks1.devtunnels.ms/resources/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 30\u001b[0m image_urls \u001b[38;5;241m=\u001b[39m \u001b[43mextract_image_urls\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Save the image URLs to a CSV file\u001b[39;00m\n\u001b[1;32m     33\u001b[0m csv_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_urls.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m, in \u001b[0;36mextract_image_urls\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_image_urls\u001b[39m(url):\n\u001b[0;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    462\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/urllib3/connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 462\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "def extract_image_urls(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "\n",
    "    image_urls = []\n",
    "    if table:\n",
    "        base_url = url.rstrip('/')  # Remove trailing slash from base URL\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[1:]:  # Skip the header row\n",
    "            columns = row.find_all('td')\n",
    "            image_url = columns[0].text.strip()\n",
    "            full_image_url = f\"{base_url}/{image_url}\"\n",
    "            image_urls.append(full_image_url)\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "def save_to_csv(image_urls, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['Image URL'])  # Write header\n",
    "        for image_url in image_urls:\n",
    "            csv_writer.writerow([image_url])\n",
    "\n",
    "url = \"https://wdw888lb-7075.uks1.devtunnels.ms/resources/\"\n",
    "image_urls = extract_image_urls(url)\n",
    "\n",
    "# Save the image URLs to a CSV file\n",
    "csv_filename = \"image_urls.csv\"\n",
    "save_to_csv(image_urls, csv_filename)\n",
    "\n",
    "print(f\"Image URLs saved to {csv_filename}\")\n",
    "print(image_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://wdw888lb-7075.uks1.devtunnels.ms/resou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://wdw888lb-7075.uks1.devtunnels.ms/resou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://wdw888lb-7075.uks1.devtunnels.ms/resou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Image URL\n",
       "0  https://wdw888lb-7075.uks1.devtunnels.ms/resou...\n",
       "1  https://wdw888lb-7075.uks1.devtunnels.ms/resou...\n",
       "2  https://wdw888lb-7075.uks1.devtunnels.ms/resou..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/hossam/python_projects/final_app_2/final_app/image_urls.csv\")\n",
    "df.iloc[:3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URLs saved to image_urls.csv\n",
      "Images downloaded and saved to search_engine_images\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extract_image_urls(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "\n",
    "    image_urls = []\n",
    "    if table:\n",
    "        base_url = url.rstrip('/')  # Remove trailing slash from base URL\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[1:]:  # Skip the header row\n",
    "            columns = row.find_all('td')\n",
    "            image_url = columns[0].text.strip()\n",
    "            full_image_url = f\"{base_url}/{image_url}\"\n",
    "            image_urls.append(full_image_url)\n",
    "\n",
    "    return image_urls\n",
    "\n",
    "def download_images(image_urls, download_folder):\n",
    "    os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "    for i, image_url in enumerate(image_urls, start=1):\n",
    "        response = requests.get(image_url)\n",
    "        image_filename = os.path.join(download_folder, f\"image_{i}.jpg\")\n",
    "\n",
    "        with open(image_filename, 'wb') as image_file:\n",
    "            image_file.write(response.content)\n",
    "\n",
    "def save_to_csv(image_urls, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['Image URL'])  # Write header\n",
    "        for image_url in image_urls:\n",
    "            csv_writer.writerow([image_url])\n",
    "\n",
    "url = \"https://wdw888lb-7075.uks1.devtunnels.ms/resources/\"\n",
    "image_urls = extract_image_urls(url)\n",
    "\n",
    "# Save the image URLs to a CSV file\n",
    "csv_filename = \"image_urls.csv\"\n",
    "save_to_csv(image_urls, csv_filename)\n",
    "\n",
    "# Download and save the images to the \"search_engine_image\" folder\n",
    "download_folder = \"search_engine_images\"\n",
    "download_images(image_urls, download_folder)\n",
    "\n",
    "print(f\"Image URLs saved to {csv_filename}\")\n",
    "print(f\"Images downloaded and saved to {download_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extract_image_info(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "\n",
    "    image_info = []\n",
    "    if table:\n",
    "        base_url = url.rstrip('/')  # Remove trailing slash from base URL\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[1:]:  # Skip the header row\n",
    "            columns = row.find_all('td')\n",
    "            image_filename = columns[0].text.strip()\n",
    "            full_image_url = f\"{base_url}/{image_filename}\"\n",
    "            image_info.append({'filename': image_filename, 'url': full_image_url})\n",
    "\n",
    "    return image_info\n",
    "\n",
    "def download_images(image_info, download_folder):\n",
    "    os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "    for info in image_info:\n",
    "        response = requests.get(info['url'])\n",
    "        image_filename = os.path.join(download_folder, info['filename'])\n",
    "\n",
    "        with open(image_filename, 'wb') as image_file:\n",
    "            image_file.write(response.content)\n",
    "\n",
    "def save_to_csv(image_info, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['Image Filename', 'Image URL'])  # Write header\n",
    "        for info in image_info:\n",
    "            csv_writer.writerow([info['filename'], info['url']])\n",
    "\n",
    "def images_in_folder(folder_path:str):\n",
    "    img_list = os.listdir(folder_path)\n",
    "    print(img_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b9ad6e18-41d7-4649-b8c2-a4a83608c25d.jpg', '81c003e2-e9cd-4fdc-a45d-a1c6239c4138.jpg', '2f91a2f7-ec3a-4605-83d4-8a8e2974c656.jpg', 'd7698c0f-7bf5-4824-9ebc-3db902db1f32.jpg', 'f08d2f8b-4254-4048-94f2-5c070e304927.jpg', '5ca17efd-86e8-42d5-a91f-b179a4a87df6.jpg', '5e7ad756-b14e-4192-a644-6ef6e0bcbbdb.jpg', 'ccaee2c8-8c3b-4fd0-9386-5ee6594e0332.jpg', '6db529d3-20ca-44ff-9134-d6163965b75a.jpg', 'd0457a22-9caa-4e58-80e6-8650c074d86a.jpg', '4e8e7478-384b-4ea8-9e5d-893949899951.jpg', '8354ce75-26cc-47a2-a3bd-e9481a40a65c.jpg', '19d5c60b-c327-433d-8e74-2752ddc0502c.jpg', '9f950845-2d69-4ff2-b07b-eb91f51f376e.jpg', '0f5faf27-e7e3-4f93-9b3c-877e9f3e6556.jpg', '0bc3a546-953c-490c-ba1e-3cd26fd0e7d4.jpg', 'd21c7e8c-cdc2-491b-97a5-d00988895141.jpg', 'c25fa6de-da52-4443-83ae-ebfe0ea49239.jpg', '3e6e75d8-3e8a-4956-b0c4-5461549851aa.jpg']\n"
     ]
    }
   ],
   "source": [
    "images_in_folder(\"search_engine_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image info saved to image_info.csv\n",
      "Images downloaded and saved to search_engine_images\n"
     ]
    }
   ],
   "source": [
    "url = \"https://wdw888lb-7075.uks1.devtunnels.ms/resources/\"\n",
    "image_info = extract_image_info(url)\n",
    "\n",
    "# Save the image info to a CSV file\n",
    "csv_filename = \"image_info.csv\"\n",
    "save_to_csv(image_info, csv_filename)\n",
    "\n",
    "# Download and save the images to the \"search_engine_images\" folder\n",
    "download_folder = \"search_engine_images\"\n",
    "download_images(image_info, download_folder)\n",
    "\n",
    "print(f\"Image info saved to {csv_filename}\")\n",
    "print(f\"Images downloaded and saved to {download_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image info saved to image_info.csv\n",
      "Images updated and saved to search_engine_images\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def extract_image_info(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "\n",
    "    image_info = []\n",
    "    if table:\n",
    "        base_url = url.rstrip('/')  # Remove trailing slash from base URL\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[1:]:  # Skip the header row\n",
    "            columns = row.find_all('td')\n",
    "            image_filename = columns[0].text.strip()\n",
    "            full_image_url = f\"{base_url}/{image_filename}\"\n",
    "            image_info.append({'filename': image_filename, 'url': full_image_url})\n",
    "\n",
    "    return image_info\n",
    "\n",
    "def download_images(image_info, download_folder):\n",
    "    os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "    for info in image_info:\n",
    "        response = requests.get(info['url'])\n",
    "        image_filename = os.path.join(download_folder, info['filename'])\n",
    "\n",
    "        with open(image_filename, 'wb') as image_file:\n",
    "            image_file.write(response.content)\n",
    "\n",
    "def save_to_csv(image_info, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['Image Filename', 'Image URL'])  # Write header\n",
    "        for info in image_info:\n",
    "            csv_writer.writerow([info['filename'], info['url']])\n",
    "\n",
    "def update_images_folder(image_info, download_folder):\n",
    "    existing_images = set(os.listdir(download_folder))\n",
    "\n",
    "    for info in image_info:\n",
    "        image_filename = info['filename']\n",
    "        image_path = os.path.join(download_folder, image_filename)\n",
    "\n",
    "        if image_filename not in existing_images:\n",
    "            # Download the image if it doesn't exist in the folder\n",
    "            response = requests.get(info['url'])\n",
    "            with open(image_path, 'wb') as image_file:\n",
    "                image_file.write(response.content)\n",
    "        else:\n",
    "            # Remove the image from the folder if it's not in image_info\n",
    "            existing_images.remove(image_filename)\n",
    "\n",
    "    # Delete images in the folder that are not present in image_info\n",
    "    for obsolete_image in existing_images:\n",
    "        obsolete_image_path = os.path.join(download_folder, obsolete_image)\n",
    "        os.remove(obsolete_image_path)\n",
    "\n",
    "url = \"https://wdw888lb-7075.uks1.devtunnels.ms/resources/\"\n",
    "image_info = extract_image_info(url)\n",
    "\n",
    "# Save the image info to a CSV file\n",
    "csv_filename = \"image_info.csv\"\n",
    "save_to_csv(image_info, csv_filename)\n",
    "\n",
    "# Update the images in the \"search_engine_images\" folder\n",
    "download_folder = \"search_engine_images\"\n",
    "update_images_folder(image_info, download_folder)\n",
    "\n",
    "print(f\"Image info saved to {csv_filename}\")\n",
    "print(f\"Images updated and saved to {download_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How are you?', 'I am fine, Thank you.', 'NO, Thanks']\n"
     ]
    }
   ],
   "source": [
    "def extract_descriptions(data):\n",
    "    # Check if the 'top_matches' key exists in the input data\n",
    "    if 'top_matches' in data:\n",
    "        # Extract descriptions from each dictionary in the 'top_matches' list\n",
    "        descriptions = [match.get('description', '') for match in data['top_matches']]\n",
    "        return descriptions\n",
    "    else:\n",
    "        print(\"Error: 'top_matches' key not found in the input data.\")\n",
    "        return []\n",
    "\n",
    "# Your variable\n",
    "output_variable = {\n",
    "    \"top_matches\": [\n",
    "        {\"description\": \"How are you?\", \"similarity_score\": 0.936392297625772},\n",
    "        {\"description\": \"I am fine, Thank you.\", \"similarity_score\": 0.6497107082656693},\n",
    "        {\"description\": \"NO, Thanks\", \"similarity_score\": 0.2503436890052259}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Call the function and print the result\n",
    "descriptions = extract_descriptions(output_variable)\n",
    "print(descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "\n",
    "class ObjectFinder:\n",
    "    def __init__(self):\n",
    "        self.translator = Translator()\n",
    "        self.nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "    def translate_to_english(self, find_object, founded_objects):\n",
    "        en_founded_objects = []\n",
    "\n",
    "        for text in founded_objects:\n",
    "            if text is not None:\n",
    "                try:\n",
    "                    source_lang = detect(text)\n",
    "                    translation_result = self.translator.translate(text, src=source_lang, dest='en')\n",
    "                    en_founded_objects.append(translation_result.text)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error translating '{text}': {str(e)}\")\n",
    "                    en_founded_objects.append(None)\n",
    "            else:\n",
    "                en_founded_objects.append(None)\n",
    "\n",
    "        try:\n",
    "            source_lang = detect(find_object)\n",
    "            en_find_object = self.translator.translate(text=find_object, src=source_lang, dest='en').text\n",
    "        except Exception as e:\n",
    "            print(f\"Error translating : {str(e)}\")\n",
    "            en_find_object = None\n",
    "\n",
    "        return en_find_object, en_founded_objects\n",
    "\n",
    "    def compare_objects_similarity(self, find_object, founded_objects):\n",
    "        find_object_doc = self.nlp(find_object)\n",
    "        similarity_scores = []\n",
    "\n",
    "        for obj in founded_objects:\n",
    "            if obj is not None:\n",
    "                obj_doc = self.nlp(obj)\n",
    "                similarity_score = find_object_doc.similarity(obj_doc)\n",
    "                similarity_scores.append((obj, similarity_score))\n",
    "            else:\n",
    "                similarity_scores.append((None, 0.0))\n",
    "\n",
    "        sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        top_matches = sorted_scores[:3]\n",
    "\n",
    "        if 'top_matches' in top_matches:\n",
    "            # Extract descriptions from each dictionary in the 'top_matches' list\n",
    "            descriptions = [match.get('description', '') for match in top_matches['top_matches']]\n",
    "            return descriptions\n",
    "        else:\n",
    "            print(\"Error: 'top_matches' key not found in the input data.\")\n",
    "            return []\n",
    "    \n",
    "class FindObjectsRequest(BaseModel):\n",
    "    find_object: str\n",
    "    founded_objects: list\n",
    "\n",
    "class FindObjectsResponse(BaseModel):\n",
    "    top_matches: list\n",
    "\n",
    "# compare text description\n",
    "@self.post(\"/find_objects\", response_model=FindObjectsResponse, tags=['Comparing Text'])\n",
    "async def find_objects(request: FindObjectsRequest):\n",
    "    print(request.dict())  # Add this line for debugging\n",
    "    try:\n",
    "        if not request.find_object:\n",
    "            raise HTTPException(status_code=400, detail=\"Please provide a description\")\n",
    "\n",
    "        en_find_object, en_founded_objects = self.object_finder.translate_to_english(\n",
    "            find_object=request.find_object, founded_objects=request.founded_objects\n",
    "        )\n",
    "        top_matches = self.object_finder.compare_objects_similarity(en_find_object, en_founded_objects)\n",
    "\n",
    "        response = {\n",
    "            \"top_matches\": top_matches\n",
    "        }\n",
    "\n",
    "        return JSONResponse(response)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muvicorn\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     \u001b[43muvicorn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m127.0.0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/uvicorn/main.py:587\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[1;32m    585\u001b[0m     Multiprocess(config, target\u001b[38;5;241m=\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun, sockets\u001b[38;5;241m=\u001b[39m[sock])\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m     \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39muds \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(config\u001b[38;5;241m.\u001b[39muds):\n\u001b[1;32m    589\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(config\u001b[38;5;241m.\u001b[39muds)  \u001b[38;5;66;03m# pragma: py-win32\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/site-packages/uvicorn/server.py:62\u001b[0m, in \u001b[0;36mServer.run\u001b[0;34m(self, sockets)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/yolov8/lib/python3.9/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "from pydantic import BaseModel\n",
    "from googletrans import Translator\n",
    "from langdetect import detect\n",
    "import spacy\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class ObjectFinder:\n",
    "    def __init__(self):\n",
    "        self.translator = Translator()\n",
    "        self.nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "    def translate_to_english(self, find_object, founded_objects):\n",
    "        en_founded_objects = []\n",
    "\n",
    "        for text in founded_objects:\n",
    "            if text is not None:\n",
    "                try:\n",
    "                    source_lang = detect(text)\n",
    "                    translation_result = self.translator.translate(text, src=source_lang, dest='en')\n",
    "                    en_founded_objects.append(translation_result.text)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error translating '{text}': {str(e)}\")\n",
    "                    en_founded_objects.append(None)\n",
    "            else:\n",
    "                en_founded_objects.append(None)\n",
    "\n",
    "        try:\n",
    "            source_lang = detect(find_object)\n",
    "            en_find_object = self.translator.translate(text=find_object, src=source_lang, dest='en').text\n",
    "        except Exception as e:\n",
    "            print(f\"Error translating : {str(e)}\")\n",
    "            en_find_object = None\n",
    "\n",
    "        return en_find_object, en_founded_objects\n",
    "\n",
    "    def compare_objects_similarity(self, find_object, founded_objects):\n",
    "        find_object_doc = self.nlp(find_object)\n",
    "        similarity_scores = []\n",
    "\n",
    "        for obj in founded_objects:\n",
    "            if obj is not None:\n",
    "                obj_doc = self.nlp(obj)\n",
    "                similarity_score = find_object_doc.similarity(obj_doc)\n",
    "                similarity_scores.append((obj, similarity_score))\n",
    "            else:\n",
    "                similarity_scores.append((None, 0.0))\n",
    "\n",
    "        sorted_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "        top_matches = sorted_scores[:3]\n",
    "\n",
    "        return top_matches\n",
    "\n",
    "class FindObjectsRequest(BaseModel):\n",
    "    find_object: str\n",
    "    founded_objects: list\n",
    "\n",
    "class FindObjectsResponse(BaseModel):\n",
    "    top_matches: list\n",
    "\n",
    "object_finder = ObjectFinder()\n",
    "\n",
    "@app.post(\"/find_objects\", response_model=FindObjectsResponse, tags=['Comparing Text'])\n",
    "async def find_objects(request: FindObjectsRequest):\n",
    "    print(request.dict())  # Add this line for debugging\n",
    "    try:\n",
    "        if not request.find_object:\n",
    "            raise HTTPException(status_code=400, detail=\"Please provide a description\")\n",
    "\n",
    "        en_find_object, en_founded_objects = object_finder.translate_to_english(\n",
    "            find_object=request.find_object, founded_objects=request.founded_objects\n",
    "        )\n",
    "        top_matches = object_finder.compare_objects_similarity(en_find_object, en_founded_objects)\n",
    "\n",
    "        response = {\n",
    "            \"top_matches\": top_matches\n",
    "        }\n",
    "\n",
    "        return JSONResponse(content=response)\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m Please Wait Model Is Loading or Downloading From Server!\n",
      "\u001b[92m Model Loaded Successfully: vgg19\n",
      "\u001b[91m Metadata and Features are already present, Do you want Extract Again? Enter yes or no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:03<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m Image Meta Information Saved: [metadata-files/vgg19/image_data_features.pkl]\n",
      "\u001b[94m Saved The Indexed File:[metadata-files/vgg19/image_features_vectors.idx]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from DeepImageSearch import Load_Data, Search_Setup\n",
    "\n",
    "# Load images from a folder\n",
    "image_list = Load_Data().from_folder(['/home/hossam/python_projects/final_app_2/final_app/folders/search_by_image'])\n",
    "\n",
    "# Set up the search engine, You can load 'vit_base_patch16_224_in21k', 'resnet50' etc more then 500+ models \n",
    "st = Search_Setup(image_list=image_list, model_name='vgg19', pretrained=True, image_count=100)\n",
    "\n",
    "# Index the images\n",
    "st.run_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Get metadata\n",
    "metadata = st.get_image_metadata_file()\n",
    "\n",
    "# Function to extract base name\n",
    "def extract_basename(file_path):\n",
    "    return os.path.basename(file_path)\n",
    "\n",
    "metadata.images_paths # .images_paths.apply(lambda x: os.path.basename(c) for c in x)\n",
    "\n",
    "metadata_list = metadata.images_paths.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/hossam/python_projects/final_app_2/final_app/folders/arabic_numbers/number_1.png', '/home/hossam/python_projects/final_app_2/final_app/folders/arabic_numbers/number_2.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m New images added to the index: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images_paths</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.0009988681, 0.0, 0.00848977, 0.0, 0.0, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0730715,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.026930243, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00545158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.011670066, 0.0, 0.0, 0.0, 0.0, 0.14928411, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013339661, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.026930243, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.0, 0.0034791813, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.0, 0.0031981417, 0.0, 0.0, 0.005843941, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.0, 0.0031981417, 0.0, 0.0, 0.005843941, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.026930243, 0.0, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.020321595, 0.0, 0.0, 0.017511886, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>/home/hossam/python_projects/final_app_2/final...</td>\n",
       "      <td>[0.022789944, 0.0, 0.0, 0.024012722, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         images_paths  \\\n",
       "0   /home/hossam/python_projects/final_app_2/final...   \n",
       "1   /home/hossam/python_projects/final_app_2/final...   \n",
       "2   /home/hossam/python_projects/final_app_2/final...   \n",
       "3   /home/hossam/python_projects/final_app_2/final...   \n",
       "4   /home/hossam/python_projects/final_app_2/final...   \n",
       "5   /home/hossam/python_projects/final_app_2/final...   \n",
       "6   /home/hossam/python_projects/final_app_2/final...   \n",
       "7   /home/hossam/python_projects/final_app_2/final...   \n",
       "8   /home/hossam/python_projects/final_app_2/final...   \n",
       "9   /home/hossam/python_projects/final_app_2/final...   \n",
       "10  /home/hossam/python_projects/final_app_2/final...   \n",
       "11  /home/hossam/python_projects/final_app_2/final...   \n",
       "12  /home/hossam/python_projects/final_app_2/final...   \n",
       "13  /home/hossam/python_projects/final_app_2/final...   \n",
       "\n",
       "                                             features  \n",
       "0   [0.0009988681, 0.0, 0.00848977, 0.0, 0.0, 0.03...  \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0730715,...  \n",
       "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.026930243, 0.0, 0....  \n",
       "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00545158...  \n",
       "4   [0.011670066, 0.0, 0.0, 0.0, 0.0, 0.14928411, ...  \n",
       "5   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013339661, 0....  \n",
       "6   [0.0, 0.0, 0.0, 0.0, 0.0, 0.026930243, 0.0, 0....  \n",
       "7   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8   [0.0, 0.0034791813, 0.0, 0.0, 0.0, 0.0, 0.0, 0...  \n",
       "9   [0.0, 0.0031981417, 0.0, 0.0, 0.005843941, 0.0...  \n",
       "10  [0.0, 0.0031981417, 0.0, 0.0, 0.005843941, 0.0...  \n",
       "11  [0.0, 0.0, 0.0, 0.0, 0.0, 0.026930243, 0.0, 0....  \n",
       "12  [0.020321595, 0.0, 0.0, 0.017511886, 0.0, 0.0,...  \n",
       "13  [0.022789944, 0.0, 0.0, 0.024012722, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_images = ['/home/hossam/python_projects/final_app_2/final_app/folders/arabic_numbers/number_1.png',\n",
    "                         '/home/hossam/python_projects/final_app_2/final_app/folders/arabic_numbers/number_2.png']\n",
    "\n",
    "\n",
    "# metadata_list = [\"metadata1\", \"metadata2\", \"metadata3\"]  # Replace with your actual metadata list\n",
    "# image_paths = [\"path1\", \"path2\", \"path3\", \"path4\"]  # Replace with your actual image paths list\n",
    "\n",
    "# Use a list comprehension to filter out elements from image_paths that are in metadata_list\n",
    "new_images = [path for path in new_images if path not in metadata_list]\n",
    "\n",
    "# Now image_paths will contain only those elements that are not in metadata_list\n",
    "print(new_images)\n",
    "\n",
    "\n",
    "# Add new images to the index\n",
    "st.add_images_to_index(new_image_paths=new_images)\n",
    "metadata = st.get_image_metadata_file()\n",
    "metadata.drop_duplicates(subset='images_paths', inplace=True)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get similar images\n",
    "st.get_similar_images(image_path='image_path', number_of_images=10)\n",
    "\n",
    "# Plot similar images\n",
    "st.plot_similar_images(image_path='image_path', number_of_images=9)\n",
    "\n",
    "# Update metadata\n",
    "metadata = st.get_image_metadata_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_images_to_index(self, image_urls: List[str]):\n",
    "    if self.st is None:\n",
    "        raise HTTPException(status_code=400, detail=\"Search engine not initialized.\")\n",
    "\n",
    "    image_paths = []\n",
    "    # Function to extract base name\n",
    "    def extract_basename(file_path):\n",
    "        return os.path.basename(file_path)\n",
    "\n",
    "    metadata.images_paths # .images_paths.apply(lambda x: os.path.basename(c) for c in x)\n",
    "\n",
    "    metadata_list = metadata.images_paths.apply(extract_basename).tolist()\n",
    "    \n",
    "    try:\n",
    "        for url in image_urls:\n",
    "            image = read_image_from_url(url)\n",
    "            filename = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "            path = os.path.join(\"folders\", \"search_by_image\", filename)\n",
    "            image.save(path)\n",
    "            image_paths.append(path)\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error downloading or saving images: {str(e)}\"}\n",
    "\n",
    "    try:\n",
    "        result = self.st.add_images_to_index(image_paths)\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error updating index: {str(e)}\"}\n",
    "\n",
    "    return {\"message\": \"Images added to index successfully.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_images_path(self, image_path, num_images=5):\n",
    "    if self.st is None:\n",
    "        raise ValueError(\"Search engine is not initialized. Call create_search_engine first.\")\n",
    "\n",
    "    # Assuming image_path is a file path, convert it to the actual image object\n",
    "    img_obj = read_image_from_url(url=image_path)\n",
    "    # Save the image to a temporary file and pass the file path\n",
    "    temp_image_path = \"temp_image.jpg\"\n",
    "    img_obj.save(temp_image_path)\n",
    "\n",
    "    similar_image_path = self.st.get_similar_images(image_path=temp_image_path, number_of_images=num_images)\n",
    "    # Convert numpy.int64 to standard Python int for serialization\n",
    "    similar_image_path = {str(key): str(value) for key, value in similar_image_path.items()}\n",
    "\n",
    "    # Remove the temporary image file\n",
    "    os.remove(temp_image_path)\n",
    "\n",
    "    return similar_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from fastapi import HTTPException\n",
    "\n",
    "def read_image_from_url(url: str) -> Image.Image:\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for errors in the HTTP response\n",
    "\n",
    "        # Check if the content is a valid image\n",
    "        if 'image' not in response.headers['content-type']:\n",
    "            raise HTTPException(status_code=500, detail=\"Invalid image format\")\n",
    "\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        return image\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Error fetching image from URL: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "image_url = \"https://wdw888lb-7075.uks1.devtunnels.ms/resources/b641fb88-7bd3-47de-ae79-4352b71050ac.jpg\"\n",
    "\n",
    "try:\n",
    "    image_data = read_image_from_url(image_url)\n",
    "    print(type(image_data))\n",
    "    # Process the image_data as needed\n",
    "except HTTPException as e:\n",
    "    print(f\"Error: {e.detail}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/hossam/python_projects/final_app_2/final_app/folders/ids/s.jpeg converted to /home/hossam/python_projects/final_app_2/final_app/folders/ids/s.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def convert_jpeg_to_jpg(image_path):\n",
    "    try:\n",
    "        # Check if the file has a \"jpeg\" extension\n",
    "        if image_path.lower().endswith(\".jpeg\"):\n",
    "            # Construct the new path with a \"jpg\" extension\n",
    "            new_path = os.path.splitext(image_path)[0] + \".jpg\"\n",
    "\n",
    "            # Rename the file\n",
    "            os.rename(image_path, new_path)\n",
    "\n",
    "            print(f\"File {image_path} converted to {new_path}\")\n",
    "        else:\n",
    "            print(\"The specified file is not a 'jpeg' file.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example usage\n",
    "image_path = \"/home/hossam/python_projects/final_app_2/final_app/folders/ids/s.jpeg\"\n",
    "convert_jpeg_to_jpg(image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
